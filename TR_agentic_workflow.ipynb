{
 "metadata": {
  "kernelspec": {
   "display_name": "snow_tru_py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "lastEditStatus": {
   "notebookId": "4tuq7f72dq5lt5syjajc",
   "authorId": "5095547476787",
   "authorName": "EBOTWICK",
   "authorEmail": "elliott.botwick@snowflake.com",
   "sessionId": "e79c0832-6945-4788-8d4e-99022a97e292",
   "lastEditTime": 1743535053545
  }
 },
 "nbformat_minor": 2,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "id": "dbec7150-dfc0-47d5-a10e-f05d5895760e",
   "metadata": {
    "language": "python",
    "name": "cell6"
   },
   "outputs": [],
   "source": "import streamlit as st\nimport pandas as pd\nimport numpy as np\nfrom faker import Faker\nimport random\nimport json\n\nfrom snowflake.snowpark.context import get_active_session\n\n\nsession = get_active_session()",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "a265202c-9003-4bcb-8b72-a6735ca9094a",
   "metadata": {
    "language": "python",
    "name": "cell4"
   },
   "outputs": [],
   "source": "#Synthetically create a dataframe of customers, products, contract val, and received revenue\nfake = Faker()\n\ndef generate_customer_data(num_customers=100):\n    \"\"\"Generates mock customer data.\"\"\"\n\n    data = []\n    product_list =[\"Cortex Search\",\"Cortex Analyst\",\n                \"DocAI\",\"Feature Store\",\n                \"Model Registry\",\"Cortex Agents\"]\n    \n    for _ in range(num_customers):\n        customer_name = fake.company()\n        products = random.sample(product_list\n,\n            random.randint(1, 4),\n        )\n        total_contract_value = round(random.uniform(1000, 100000), 2)\n        revenue_received = round(random.uniform(0, total_contract_value), 2)\n\n        data.append(\n            {\n                \"Customer\": customer_name,\n                \"Total_Contract_Value\": total_contract_value,\n                \"Revenue_Received\": revenue_received,\n                \"Products_List\": products,\n\n            }\n        )\n    df = pd.DataFrame(data)\n\n    for product in product_list:\n        df[f\"{product.replace(' ', '_')}_User\"] = df['Products_List'].apply(lambda x: 'Y' if product in x else 'N')\n\n    # df = df[[\"Customer\",\"Products_List\", \"Cortex_Search_user\", \"Cortex_Analyst_user\", \n    # \"DocAI_user\", \"Feature_Store_user\", \"Model_Registry_user\", \"Cortex_Agents_user\",\n    # \"Total_Contract_Value\", \"Revenue_Received\"]]\n\n    # df = df[[\"Customer\",\"Products_List\",\"Model_Registry_User\",\n    #         \"Cortex_Search_User\",\"Feature_Store_User\",\"Cortex_Agents_User\",\n    #         \"Total_Contract_Value\",\"Revenue_Received\"]]\n\n    return df\n\n# Generate and display the DataFrame\ndf = generate_customer_data()\ndf.head()\ndf.columns",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "7884aebc-e85a-4a67-8664-4664d98b9ac2",
   "metadata": {
    "language": "python",
    "name": "cell12"
   },
   "outputs": [],
   "source": "df.head()",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "97ce10d6-35e8-429c-93a2-26559beb239e",
   "metadata": {
    "language": "python",
    "name": "cell5"
   },
   "outputs": [],
   "source": "session.write_pandas(df, \"CUSTOMER_PRODUCT_DATA\", auto_create_table=True, quote_identifiers = False, overwrite=True)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "5e401c13-7f55-4da9-9846-b2da6b8c23ba",
   "metadata": {
    "language": "sql",
    "name": "cell8"
   },
   "outputs": [],
   "source": "SHOW TABLES;",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "778a1d23-ddb6-4b8b-aee4-1feb7aef72b0",
   "metadata": {
    "language": "sql",
    "name": "cell1"
   },
   "outputs": [],
   "source": "CREATE OR REPLACE STAGE SEMANTIC DIRECTORY = ( ENABLE = true );",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "7acc6bf4-45ac-49e0-b535-ae64fc4d2ada",
   "metadata": {
    "name": "cell7"
   },
   "source": ""
  },
  {
   "cell_type": "markdown",
   "id": "4720f417-0bdf-4990-b36e-99f0a96c9c58",
   "metadata": {
    "name": "create_semantic_model_via_UI",
    "collapsed": false
   },
   "source": "# We will now create the semantic model to query our new data with natural language\n\n* To do so, first go to the AI Studio in snowsight and click the Cortex Analyst Tab\n\n* Choose the appropriate database and schema the select the SEMANTIC stage we just created\n\n* Click Create New\n\n* Fill out the Description - \n    * \"Semantic model containing information about customer product data including the customer name, which products they currently use, their total contract value, and the amount of revenue we have received from the customer\"\n\n* Select the CUSTOMER_PRODUCT_DATA table and select all columns\n"
  },
  {
   "cell_type": "code",
   "id": "22d4c5b0-b88e-4109-91c9-0d5b99553428",
   "metadata": {
    "language": "python",
    "name": "cell10"
   },
   "outputs": [],
   "source": "data = session.table(\"CUSTOMER_PRODUCT_DATA\")\ndata.show(3)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "5998dc6b-f680-48fd-9d30-6644541e98ac",
   "metadata": {
    "language": "python",
    "name": "cell9"
   },
   "outputs": [],
   "source": "## Start testing cortex analyst api call here\nfrom typing import List, Dict, Optional\nimport _snowflake\n\n\nclass CortexAnalyst():\n    def __init__(self, db: str, schema: str, stage: str, semantic_model_file_path: str):\n        self.db = db\n        self.schema = schema\n        self.stage = stage\n        self.semantic_model_file_path = semantic_model_file_path\n\n\n    # @instrument\n    def send_message(self, prompt: str) -> dict:\n\n        \"\"\"Calls the REST API and returns the response.\"\"\"\n        \n        messages = []\n        messages.append({\"role\": \"user\", \"content\": [{\"type\": \"text\", \"text\": prompt}]})\n        request_body = {\n            \"messages\": messages, #need to wrap in a list?\n            \"semantic_model_file\": f\"@{self.db}.{self.schema}.{self.stage}/{self.semantic_model_file_path}\",\n        }\n\n        print(request_body)\n\n        resp = _snowflake.send_snow_api_request(\n            \"POST\",\n            f\"/api/v2/cortex/analyst/message\",\n            {},\n            {},\n            request_body,\n            {},\n            30000,\n        )\n        if resp[\"status\"] < 400:\n            return json.loads(resp[\"content\"])\n        else:\n            # messages.pop()\n            raise Exception(\n                f\"Failed request with status {resp['status']}: {resp}\"\n            )\n    # @instrument\n    def process_message(self, prompt: str) -> None:\n        \"\"\"Processes a message and adds the response to the chat.\"\"\"\n        messages=[]\n        messages.append(\n            {\"role\": \"user\", \"content\": [{\"type\": \"text\", \"text\": prompt}]}\n        )\n        with st.chat_message(\"user\"):\n            st.markdown(prompt)\n        with st.chat_message(\"assistant\"):\n            with st.spinner(\"Generating response...\"):\n                # response = \"who had the most rec yards week 10\"\n                response = self.send_message(prompt=prompt)\n                request_id = response[\"request_id\"]\n                content = response[\"message\"][\"content\"]\n                messages.append(\n                    {**response['message'], \"request_id\": request_id}\n                )\n        return self.display_content(content=content, request_id=request_id)  # type: ignore[arg-type]\n        # return response\n    \n    # @instrument\n    def display_content(self,\n        content: List[Dict[str, str]],\n        request_id: Optional[str] = None,\n        message_index: Optional[int] = None,\n    ) -> None:\n        \"\"\"Displays a content item for a message.\"\"\"\n        message_index = message_index or len(prompt)\n        if request_id:\n            with st.expander(\"Request ID\", expanded=False):\n                st.markdown(request_id)\n        for item in content:\n            if item[\"type\"] == \"text\":\n                st.markdown(item[\"text\"])\n            elif item[\"type\"] == \"suggestions\":\n                with st.expander(\"Suggestions\", expanded=True):\n                    for suggestion_index, suggestion in enumerate(item[\"suggestions\"]):\n                        if st.button(suggestion, key=f\"{message_index}_{suggestion_index}\"):\n                            st.session_state.active_suggestion = suggestion\n            elif item[\"type\"] == \"sql\":\n                return self.display_sql(item[\"statement\"])\n\n    # @instrument\n    def display_sql(self, sql: str) -> None:\n        with st.expander(\"SQL Query\", expanded=False):\n            st.code(sql, language=\"sql\")\n        with st.expander(\"Results\", expanded=True):\n            with st.spinner(\"Running SQL...\"):\n                session = get_active_session()\n                df = session.sql(sql).to_pandas()\n                if len(df.index) > 1:\n                    data_tab, line_tab, bar_tab = st.tabs(\n                        [\"Data\", \"Line Chart\", \"Bar Chart\"]\n                    )\n                    data_tab.dataframe(df)\n                    if len(df.columns) > 1:\n                        df = df.set_index(df.columns[0])\n                    with line_tab:\n                        st.line_chart(df)\n                    with bar_tab:\n                        st.bar_chart(df)\n                else:\n                    st.dataframe(df)\n\n        return df\n\nCA = CortexAnalyst(db='TR_MULTI_AGENT', schema='PUBLIC', stage='SEMANTIC', semantic_model_file_path='customer_product_data_model.yaml')",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "a2252f77-2fea-4ee4-b3e5-beb7e9bbefc2",
   "metadata": {
    "language": "python",
    "name": "cell14"
   },
   "outputs": [],
   "source": "CA_response = CA.process_message(prompt='Show me all the products for Morgan-Love')",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "711abaeb-96cc-4925-b63c-27e767aa1544",
   "metadata": {
    "language": "python",
    "name": "cell3"
   },
   "outputs": [],
   "source": "# from googlesearch import search\nimport requests\nfrom bs4 import BeautifulSoup\n\ndef get_top_article_text(company_name):\n    \"\"\"\n    Performs a Google search for a company name and returns the raw text of the\n    top three articles.\n\n    Args:\n        company_name (str): The name of the company to search for.\n\n    Returns:\n        list: A list of strings, where each string is the raw text of an article,\n              or an empty list if an error occurs.\n    \"\"\"\n    try:\n\n        article_texts = []\n        for url in search_results:\n            try:\n                response = requests.get(url, timeout=10) #added timeout\n                response.raise_for_status() # Raise HTTPError for bad responses (4xx or 5xx)\n                soup = BeautifulSoup(response.content, 'html.parser')\n                text = soup.get_text(separator=' ', strip=True) #added separator and strip\n                article_texts.append(text)\n            except requests.exceptions.RequestException as e:\n                print(f\"Error fetching URL {url}: {e}\")\n            except Exception as e:\n                print(f\"Error processing URL {url}: {e}\")\n\n        return article_texts\n\n    except Exception as e:\n        print(f\"Error during search: {e}\")\n        return []\n\n# Example usage:\ncompany = \"Snowflake\"\narticle_texts = get_top_article_text(company)\n\nif article_texts:\n    for i, text in enumerate(article_texts):\n        print(f\"Article {i+1}:\\n{text}\\n{'-'*40}\\n\")\nelse:\n    print(\"Could not retrieve article text.\")",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "name": "cell2",
    "language": "python"
   },
   "outputs": [],
   "source": "class Multi_Agent_App:\n\n    def agent_1_cortex_analyst(self, client: str) -> list:\n        \"\"\"\n        takes client and inserts into predefined prompt and passes to cortex analyst to return list of products client uses today\n        \"\"\"\n        resp = CA.process_message(f\"What products are being used by our client {client}\")\n\n        products = resp.iloc[:,0].to_list()\n\n        return products\n\n    def agent_2_client_web_serach(self, client: str) -> list:\n        \"\"\" \n        calls api to google client name and return top three news articles. \n        Potentially use bs4 or similar library to parse web results\n        Return list of web page text (or potentially pass to LLM to generate summary)\n        \"\"\"\n\n        api_key = os.environ.get(\"GOOGLE_API_KEY\")\n        cse_id = os.environ.get(\"GOOGLE_CSE_ID\")\n\n        web_query = f\"top news for {client}\"\n        url = \"https://www.googleapis.com/customsearch/v1\"\n        params = {\n            \"key\": api_key,\n            \"cx\": cse_id,\n            \"q\": web_query,\n            \"num\": 3\n        }\n\n        top_3_results = requests.get(url, params=params)\n\n        news_summary_list = []\n\n        for result in top_3_result:\n            news_summaries_list.append(complete('claude-3-5-sonnet', f'summarize the following web page {result}'))\n\n        return news_summaries_list\n\n\n    def agent_3_market_web_serach(self, client: str) -> list:\n        \"\"\" \n        uses an llm to determine client industry, then ues api to google client industry and return top three articles. \n        Potentially use bs4 or similar library to parse web results\n        Return list of web page text (or potentially pass to LLM to generate summary)\n        \"\"\"\n        api_key = os.environ.get(\"GOOGLE_API_KEY\")\n        cse_id = os.environ.get(\"GOOGLE_CSE_ID\")\n\n        client_market = complete('claude-3-5-sonnet', f'what is the most applicable market for the company {client}')\n\n        web_query = f\"market news for {client_market}\"\n        url = \"https://www.googleapis.com/customsearch/v1\"\n        params = {\n            \"key\": api_key,\n            \"cx\": cse_id,\n            \"q\": web_query,\n            \"num\": 3\n        }\n\n        top_3_results = requests.get(url, params=params)\n\n        market_news_summary_list = []\n\n        for result in top_3_result:\n            market_news_summary_list.append(complete('claude-3-5-sonnet', f'summarize the following web page {result}'))\n\n        return market_news_summary_list\n\n    def agent_4_prep_pitch(self, client: str) -> str:\n        \"\"\" \n        passes products, client news, and market news to an LLM to come up with a rough prep pitch\n\n        \"\"\"\n        products = self.agent_1_cortex_analyst(client)\n        client_news = self.agent_2_client_web_serach(client)\n        market_news = self.agent_3_market_web_serach(client)\n        prep_pitch = complete('claude-3-5-sonnet', \n                              f\"\"\"\n                              prepare a product pitch based on the following products being used and the client and market news \n                              products_used: {products}\n                              client_news: {client_news}\n                              market_news: {market_news}\n                              \"\"\")\n        return prep_pitch\n    \n    def agent_5_disco_questions(self, client: str) -> str:\n        \"\"\" \n        passes products, client news, and market news to an LLM to come up with a list of appropriate discovery questions\n        \"\"\"\n        products = self.agent_1_cortex_analyst(client)\n        client_news = self.agent_2_client_web_serach(client)\n        market_news = self.agent_3_market_web_serach(client)\n        prep_pitch = complete('claude-3-5-sonnet', \n                              f\"\"\"\n                              prepare a set of discovery questions for a client the following products being used and the client and market news \n                              products_used: {products}\n                              client_news: {client_news}\n                              market_news: {market_news}\n                              \"\"\")\n        return prep_pitch\n\n\n    def orchestrate_all_agents(self, client: str, output_file_name: str):\n        \"\"\" \n        primary function that \n        \"\"\"\n        products = self.agent_1_cortex_analyst(client)\n        client_news = self.agent_2_client_web_serach(client)\n        market_news = self.agent_3_market_web_serach(client)\n        pitch = self.agent_4_prep_pitch(client)\n        disco_questions = self.agent_5_disco_questions(client)\n\n        markdown_doc = \"Products \\n\" + ' '.join(products) + \\\n                       \"\\n\\n Client News \\n \" + ' '.join(client_news)+ \\\n                       \"\\n\\n Market News \\n \" + ' '.join(market_news) + \\\n                       \"\\n\\n Pitch \\n \" + pitch + \\\n                       \"\\n\\n Disco Questions \\n \" + disco_questions\n\n        with open(output_file_name, \"w\", encoding=\"utf-8\") as f:\n            f.write(markdown_doc)\n\n        print(f\"Client prep file written to {output_file_name}!\")\n\n        return products, client_news, market_news, pitch, disco_questions",
   "id": "ce110000-1111-2222-3333-ffffff000001"
  }
 ]
}