{
 "metadata": {
  "kernelspec": {
   "display_name": "snow_tru_py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "lastEditStatus": {
   "notebookId": "4tuq7f72dq5lt5syjajc",
   "authorId": "5095547476787",
   "authorName": "EBOTWICK",
   "authorEmail": "elliott.botwick@snowflake.com",
   "sessionId": "d6271eea-de68-4c2f-9c35-d2a059b22ae0",
   "lastEditTime": 1743790184332
  }
 },
 "nbformat_minor": 2,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "id": "dbec7150-dfc0-47d5-a10e-f05d5895760e",
   "metadata": {
    "language": "python",
    "name": "imports"
   },
   "outputs": [],
   "source": "import streamlit as st\nimport pandas as pd\nimport numpy as np\nimport random\nimport json\n\nfrom snowflake.cortex import complete\nfrom snowflake.snowpark.context import get_active_session\n\nsession = get_active_session()",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "a265202c-9003-4bcb-8b72-a6735ca9094a",
   "metadata": {
    "language": "python",
    "name": "generate_dataset",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "#Synthetically create a dataframe of customers, products, contract val, and received revenue\n\ndef generate_customer_data():\n    \"\"\"Generates mock customer data.\"\"\"\n\n    data = []\n    product_list =[\"Cortex LLM\",\"Cortex Search\",\n                   \"Cortex Analyst\",\"Cortex Agents\",\n                \"DocAI\",\"Model Registry\"]\n\n\n    customer_list = [\"Apple\", \"Amazon\", \"Microsoft\", \"Alphabet\", \"Google\", \"Facebook\", \"Procter & Gamble\", \"Coca-Cola\", \n                         \"ExxonMobil\", \"Verizon\", \"Johnson & Johnson\", \"Pfizer\", \"UnitedHealth Group\", \"Caterpillar\", \n                         \"3M\", \"Chevron\", \"Walmart\", \"McDonald's\", \"AT&T\", \"Berkshire Hathaway\", \"Sears Holdings\", \"Cargill\", \"DuPont\", \n                         \"General Electric\", \"Merck\", \"Visa\", \"Intel\", \"Cisco Systems\", \"Wealthsimple\", \"Snowflake\"]\n        \n    for i in customer_list:\n        customer_name = i\n        products_used = random.sample(product_list\n,\n            random.randint(1, 4),\n        )\n        selected_product = random.sample(product_list, 1)[0]\n        total_contract_value = round(random.uniform(1000, 100000), 2)\n        revenue_received = round(random.uniform(0, total_contract_value), 2)\n\n        data.append(\n            {\n                \"CUSTOMER\": customer_name,\n                \"TOTAL_CONTRACT_VALUE\": total_contract_value,\n                \"REVENUE_RECEIVED\": revenue_received,\n                \"PRODUCTS_USED\": products_used,\n                \"PROPENSITY_MODEL_SUGGESTED_PRODUCT\": selected_product,\n\n            }\n        )\n    df = pd.DataFrame(data)\n    return df\n\n# Generate and display the DataFrame\ndf = generate_customer_data()\ndf.tail(10)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "97ce10d6-35e8-429c-93a2-26559beb239e",
   "metadata": {
    "language": "python",
    "name": "write_data_to_snowflake"
   },
   "outputs": [],
   "source": "# session.write_pandas(df, \"CUSTOMER_DATA\", auto_create_table=True, quote_identifiers = False, overwrite=False)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "b190b73b-155b-45c2-9218-c024bb028851",
   "metadata": {
    "language": "python",
    "name": "create_conversations"
   },
   "outputs": [],
   "source": "from datetime import datetime, timedelta\n\n# Simulated conversation transcripts\nconversations = [\n    # VP of Data - Conversation 1\n    \"\"\"[Meeting 1 - VP of Data, Wealthsimple | Topic: Data Lake Modernization, Analytics Acceleration]\nSnowflake AE: Thanks for joining today. You mentioned you’re still on Hadoop—what pain are you seeing?\nVP of Data: Honestly, it's been a bottleneck for years. Query latency is brutal. Our analysts can't move fast.\nSnowflake AE: We’re seeing a lot of Hadoop-to-Snowflake migrations. What’s been holding you back?\nVP of Data: Concerns about cost and performance at scale. We ingest terabytes daily.\nSnowflake AE: Totally get that. Our consumption model plus auto-suspend can help manage cost. Want me to run a TCO comparison?\nVP of Data: Yeah, that’d be helpful. Also curious about how real-time our analytics could become.\nSnowflake AE: Real-time dashboards with Snowpipe and Streams & Tasks are common. Let’s show you a live demo.\nVP of Data: Okay, impressed so far. Let’s talk next week after your cost model.\n\"\"\",\n    # VP of Data - Conversation 2\n    \"\"\"[Meeting 2 - VP of Data, Wealthsimple | Topic: Generative AI Exploration]\nSnowflake AE: Following up on our last call. How’d the demo land internally?\nVP of Data: Leadership loved it. But now GenAI is on their radar—everyone wants to build an LLM chatbot.\nSnowflake AE: We’re helping several fintechs with private LLM deployments using Cortex and Secure Views.\nVP of Data: Sounds promising, but security and governance are massive concerns.\nSnowflake AE: Understandable. Cortex stays inside your VPC and supports full masking and RBAC.\nVP of Data: Okay, still skeptical. Our infosec team is very conservative.\nSnowflake AE: Want me to bring in a customer who’s built something similar?\nVP of Data: Yes, that might help. We’re intrigued, but cautious.\n\"\"\",\n    # Director of ML - Conversation 1\n    \"\"\"[Meeting 1 - Director of ML, Wealthsimple | Topic: Model Training at Scale]\nSnowflake AE: Appreciate you making time—what’s the biggest pain in your ML workflow?\nDirector of ML: Training time. Our pipelines are running for 8–12 hours. We need faster iterations.\nSnowflake AE: We’ve helped other customers use Snowpark for distributed model training. Have you tried that?\nDirector of ML: Only for batch inference. Unsure how it scales for training.\nSnowflake AE: We can set up a pilot using your current data and run side-by-sides.\nDirector of ML: Alright, I’m open to that. But if it’s slower or pricier, it’ll be a tough sell.\nSnowflake AE: That’s fair. I’ll also bring in our solutions architect to map your pipeline.\nDirector of ML: Do that. Time is money for us.\n\"\"\",\n    # Director of ML - Conversation 2\n    \"\"\"[Meeting 2 - Director of ML, Wealthsimple | Topic: Model Monitoring and Feature Store]\nSnowflake AE: Hey, quick check-in—how’d the training pilot go?\nDirector of ML: Honestly? Meh. Performance was okay, but costs were higher than expected.\nSnowflake AE: That’s good feedback. We can optimize the warehouse scaling and see better results.\nDirector of ML: I’m more excited about your feature store integration though.\nSnowflake AE: Ah, using Snowpark and Unity Catalog to reuse features across teams?\nDirector of ML: Exactly. Right now it’s chaos—duplication everywhere.\nSnowflake AE: Let’s run a workshop to map your feature pipeline and centralize it.\nDirector of ML: Book it. That’s something I can champion internally.\n\"\"\",\n    # Director of ML - Conversation 3\n    \"\"\"[Meeting 3 - Director of ML, Wealthsimple | Topic: LLM Proof of Concept]\nSnowflake AE: You mentioned exploring a generative model for client interaction—how’s that progressing?\nDirector of ML: Leadership’s pushing hard. But legal is nervous about hallucinations and brand risk.\nSnowflake AE: We’ve seen success using Retrieval-Augmented Generation (RAG) with curated content.\nDirector of ML: That could help. But who curates the content? Our data team is swamped.\nSnowflake AE: We can help stand up a content pipeline and fine-tune on internal docs.\nDirector of ML: Okay, now you’re talking. Let’s draft a project plan.\nSnowflake AE: Perfect, I’ll bring our AI architect to the next session.\nDirector of ML: And please prep something I can take to Legal—before they kill this thing.\n\"\"\"\n]\n\n# Create a DataFrame with a single column for the conversations\ndf = pd.DataFrame(conversations, columns=[\"transcript\"])\n\n# Start date in October 2024\nstart_date = datetime(2024, 10, 1)\ndate_list = [start_date + timedelta(days=i*7) for i in range(len(conversations))]\n\n# Person and title based on the conversation order\nnames_and_titles = [\n    (\"Jordan Michaels\", \"VP of Data\"),\n    (\"Jordan Michaels\", \"VP of Data\"),\n    (\"Ravi Desai\", \"Director of ML\"),\n    (\"Ravi Desai\", \"Director of ML\"),\n    (\"Ravi Desai\", \"Director of ML\")\n]\n\n# Add new columns\ndf[\"date\"] = [d.strftime(\"%Y-%m-%d\") for d in date_list]\ndf[\"customer\"] = \"Wealthsimple\"\ndf[\"name\"] = [name for name, title in names_and_titles]\ndf[\"title\"] = [title for name, title in names_and_titles]\n\n\nsession.write_pandas(df, \"CUSTOMER_CONVERSATIONS\", auto_create_table=True, quote_identifiers = False, overwrite=True)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "5e401c13-7f55-4da9-9846-b2da6b8c23ba",
   "metadata": {
    "language": "sql",
    "name": "show_tables"
   },
   "outputs": [],
   "source": "SHOW TABLES;",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "9bde8d4a-d49b-48c9-a862-e5ddfd9de58a",
   "metadata": {
    "language": "sql",
    "name": "cell7",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "Alter table customer_conversations add column SUMMARY VARIANT",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "fe449f19-48bc-4241-bba3-c5aa593f2a35",
   "metadata": {
    "language": "sql",
    "name": "batch_sql_processing",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "update customer_conversations AS cc\nSET summary = PARSE_JSON((\n    SELECT snowflake.cortex.complete(\n        'claude-3-5-sonnet',\n        [\n            {\n                'role': 'user',\n                'content': concat(\n                    'Read the following conversation and summarize it into a semistructured object:\\n\n                    List the products discussed in an array/n\n                    In one sentence indicate the pain mentioned from the customer/n\n                    In one sentence summarize the customer objections/n\n                    In one sentence summarize the next steps.',\n                    cc.transcript\n                )\n            }\n        ],\n        {\n            'temperature': 0,\n            'max_tokens': 1000,\n            'response_format': {\n                'type': 'json',\n                'schema': {\n                    'type': 'object',\n                    'properties': {\n                        'products_discussed': {\n                            'type': 'array',\n                            'items': { 'type': 'string' }\n                        },\n                        'pain_mentioned': { 'type': 'string' },\n                        'objections': { 'type': 'string' },\n                        'next_steps': { 'type': 'string' }\n                    },\n                    'required': [\n                        'products_discussed',\n                        'pain_mentioned',\n                        'objections',\n                        'next_steps'\n                    ]\n                }\n            }\n        }\n    ):structured_output[0].raw_message\n));\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "38011f6c-9323-44d2-8758-e7e8892b17d4",
   "metadata": {
    "language": "sql",
    "name": "cell8",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "select * from customer_conversations;",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "778a1d23-ddb6-4b8b-aee4-1feb7aef72b0",
   "metadata": {
    "language": "sql",
    "name": "create_stage"
   },
   "outputs": [],
   "source": "CREATE STAGE IF NOT EXISTS SEMANTIC DIRECTORY = ( ENABLE = true );",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "4720f417-0bdf-4990-b36e-99f0a96c9c58",
   "metadata": {
    "name": "create_semantic_model_via_UI",
    "collapsed": false
   },
   "source": "# We will now create the semantic model to query our new data with natural language\n\n* To do so, first go to the AI Studio in snowsight and click the Cortex Analyst Tab\n\n* Choose the appropriate database and schema the select the SEMANTIC stage we just created\n\n* Click Create New\n\n* Fill out the Description - \n    * \"Semantic model containing information about customer product data including the customer name, which products they currently use, their total contract value, and the amount of revenue we have received from the customer\"\n\n* Select the CUSTOMER_PRODUCT_DATA table and select all columns\n"
  },
  {
   "cell_type": "code",
   "id": "22d4c5b0-b88e-4109-91c9-0d5b99553428",
   "metadata": {
    "language": "python",
    "name": "load_data"
   },
   "outputs": [],
   "source": "data = session.table(\"CUSTOMER_DATA\")\ndata.show(5)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "5998dc6b-f680-48fd-9d30-6644541e98ac",
   "metadata": {
    "language": "python",
    "name": "define_cortex_analyst_class"
   },
   "outputs": [],
   "source": "## Start testing cortex analyst api call here\nfrom typing import List, Dict, Optional\nimport _snowflake\n\n\nclass CortexAnalyst():\n    def __init__(self, db: str, schema: str, stage: str, semantic_model_file_path: str):\n        self.db = db\n        self.schema = schema\n        self.stage = stage\n        self.semantic_model_file_path = semantic_model_file_path\n\n\n    # @instrument\n    def send_message(self, prompt: str) -> dict:\n\n        \"\"\"Calls the REST API and returns the response.\"\"\"\n        \n        messages = []\n        messages.append({\"role\": \"user\", \"content\": [{\"type\": \"text\", \"text\": prompt}]})\n        request_body = {\n            \"messages\": messages, #need to wrap in a list?\n            \"semantic_model_file\": f\"@{self.db}.{self.schema}.{self.stage}/{self.semantic_model_file_path}\",\n        }\n\n        print(request_body)\n\n        resp = _snowflake.send_snow_api_request(\n            \"POST\",\n            f\"/api/v2/cortex/analyst/message\",\n            {},\n            {},\n            request_body,\n            {},\n            30000,\n        )\n        if resp[\"status\"] < 400:\n            return json.loads(resp[\"content\"])\n        else:\n            # messages.pop()\n            raise Exception(\n                f\"Failed request with status {resp['status']}: {resp}\"\n            )\n    # @instrument\n    def process_message(self, prompt: str) -> None:\n        \"\"\"Processes a message and adds the response to the chat.\"\"\"\n        messages=[]\n        messages.append(\n            {\"role\": \"user\", \"content\": [{\"type\": \"text\", \"text\": prompt}]}\n        )\n        with st.chat_message(\"user\"):\n            st.markdown(prompt)\n        with st.chat_message(\"assistant\"):\n            with st.spinner(\"Generating response...\"):\n                # response = \"who had the most rec yards week 10\"\n                response = self.send_message(prompt=prompt)\n                request_id = response[\"request_id\"]\n                content = response[\"message\"][\"content\"]\n                messages.append(\n                    {**response['message'], \"request_id\": request_id}\n                )\n        return self.display_content(content=content, request_id=request_id, prompt = prompt)  # type: ignore[arg-type]\n        # return response\n    \n    # @instrument\n    def display_content(self,\n        content: List[Dict[str, str]],\n        request_id: Optional[str] = None,\n        message_index: Optional[int] = None,\n        prompt: Optional[str] = None,\n    ) -> None:\n        \"\"\"Displays a content item for a message.\"\"\"\n        message_index = message_index or len(prompt)\n        # if request_id:\n            # with st.expander(\"Request ID\", expanded=False):\n                # st.markdown(request_id)\n        for item in content:\n            if item[\"type\"] == \"text\":\n                st.markdown(item[\"text\"])\n            elif item[\"type\"] == \"suggestions\":\n                with st.expander(\"Suggestions\", expanded=True):\n                    for suggestion_index, suggestion in enumerate(item[\"suggestions\"]):\n                        if st.button(suggestion, key=f\"{message_index}_{suggestion_index}\"):\n                            st.session_state.active_suggestion = suggestion\n            elif item[\"type\"] == \"sql\":\n                return self.display_sql(item[\"statement\"])\n\n    # @instrument\n    def display_sql(self, sql: str) -> None:\n        with st.expander(\"SQL Query\", expanded=False):\n            st.code(sql, language=\"sql\")\n        with st.expander(\"Results\", expanded=True):\n            with st.spinner(\"Running SQL...\"):\n                session = get_active_session()\n                df = session.sql(sql).to_pandas()\n                if len(df.index) > 1:\n                    data_tab, line_tab, bar_tab = st.tabs(\n                        [\"Data\", \"Line Chart\", \"Bar Chart\"]\n                    )\n                    data_tab.dataframe(df)\n                    if len(df.columns) > 1:\n                        df = df.set_index(df.columns[0])\n                    with line_tab:\n                        st.line_chart(df)\n                    with bar_tab:\n                        st.bar_chart(df)\n                else:\n                    st.dataframe(df)\n\n        return df\n\nCA = CortexAnalyst(db='TR_MULTI_AGENT', schema='PUBLIC', stage='SEMANTIC', semantic_model_file_path='customer_data.yaml')",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "a2252f77-2fea-4ee4-b3e5-beb7e9bbefc2",
   "metadata": {
    "language": "python",
    "name": "test_CA",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "CA_response = CA.process_message(prompt='Show me all the products for Wealthsimple')",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ca3f9fe5-35bd-4c8d-b6f8-cc75084e29d8",
   "metadata": {
    "language": "python",
    "name": "test_suggested_product_CA"
   },
   "outputs": [],
   "source": "CA_response_2 = CA.process_message(prompt='Which product should I pitch to Welathsimple?')",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "9ab01bd9-435d-4d62-9e35-5c931321ace9",
   "metadata": {
    "name": "Cortex_Search_Section",
    "collapsed": false
   },
   "source": "## Define Retrieval Service\n### Get up to date product info and customer references on products to inform sales pitches"
  },
  {
   "cell_type": "code",
   "id": "4410f6a5-fa90-4f4c-a0db-a19927b70b3f",
   "metadata": {
    "language": "sql",
    "name": "list_docs"
   },
   "outputs": [],
   "source": "LS @DOCUMENTS",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "3ab2c62a-406e-44c3-bc65-2be40cf1e1fd",
   "metadata": {
    "language": "sql",
    "name": "create_doc_table"
   },
   "outputs": [],
   "source": "CREATE TABLE TR_MULTI_AGENT.PUBLIC.DOC_TEXT_TABLE IF NOT EXISTS (relative_path VARCHAR(500), raw_text VARIANT);",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "8631a3ab-1c57-4cc8-897c-56878141cd0f",
   "metadata": {
    "language": "sql",
    "name": "parse_pdfs_into_doc_table"
   },
   "outputs": [],
   "source": "INSERT INTO TR_MULTI_AGENT.PUBLIC.DOC_TEXT_TABLE (relative_path, raw_text)\nWITH html_files AS (\n    SELECT DISTINCT\n        METADATA$FILENAME AS relative_path\n    FROM @TR_MULTI_AGENT.PUBLIC.DOCUMENTS\n    -- WHERE METADATA$FILENAME ILIKE '%.pdf'\n    --   -- Exclude files that have already been parsed\n      WHERE METADATA$FILENAME NOT IN (SELECT relative_path FROM DOC_TEXT_TABLE)\n)\nSELECT \n    relative_path,\n    SNOWFLAKE.CORTEX.PARSE_DOCUMENT(\n        '@TR_MULTI_AGENT.PUBLIC.DOCUMENTS',  -- Your stage name\n        relative_path,  -- File path\n        {'mode': 'layout'}  -- Adjust mode as needed ('layout', 'ocr')\n    ) AS raw_text\nFROM html_files;",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c35d88d0-db35-4f9a-97d7-76ff410e2f4b",
   "metadata": {
    "language": "sql",
    "name": "chunk_docs"
   },
   "outputs": [],
   "source": "CREATE TABLE IF NOT EXISTS TR_MULTI_AGENT.PUBLIC.DOC_CHUNKS_TABLE AS\nWITH text_chunks AS (\n    SELECT\n        relative_path,\n        SNOWFLAKE.CORTEX.SPLIT_TEXT_RECURSIVE_CHARACTER(\n            raw_text:content::STRING,  -- Extract the 'content' field from the JSON\n            'markdown',    -- Adjust to 'markdown' if needed\n            2000,       -- Adjust chunk size\n            100,       -- Adjust overlap size\n            ['\\n\\n']     -- Adjust separators\n        ) AS chunks\n    FROM TR_MULTI_AGENT.PUBLIC.DOC_TEXT_TABLE\n)\nSELECT\n    relative_path,\n    c.value AS chunk,\n    (relative_path || ' ' || chunk) AS SEARCH_COL\nFROM text_chunks,\nLATERAL FLATTEN(INPUT => chunks) c;",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c68854b1-a0ab-4c31-af06-f564c27bc764",
   "metadata": {
    "language": "python",
    "name": "view_chunked_docs_table"
   },
   "outputs": [],
   "source": "chunk_df = session.table('TR_MULTI_AGENT.PUBLIC.DOC_CHUNKS_TABLE')\nchunk_df.show(3)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "74c5e9ec-2b7a-4b9c-945e-4f71edc7b6d9",
   "metadata": {
    "language": "sql",
    "name": "create_search_service"
   },
   "outputs": [],
   "source": "CREATE OR REPLACE CORTEX SEARCH SERVICE TR_MULTI_AGENT.PUBLIC.PRODUCT_INFO_SEARCH\n    ON SEARCH_COL\n    WAREHOUSE = DEFAULT_XS\n    TARGET_LAG = '365 days'\n    AS SELECT \n        RELATIVE_PATH,\n        CHUNK,\n        SEARCH_COL\nFROM TR_MULTI_AGENT.PUBLIC.DOC_CHUNKS_TABLE",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c3b69c81-cdd2-409c-acc0-24c6accf82a8",
   "metadata": {
    "language": "python",
    "name": "test_RAG",
    "collapsed": false,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "from typing import List\nfrom snowflake.core import Root\nproduct = \"Cortex Search\"\nprompt = f\"Retrieve relevant documentation for {product}\"\n\nroot = Root(session)\ncortex_search_service = (\n    root\n    .databases[\"TR_MULTI_AGENT\"]\n    .schemas[\"PUBLIC\"]\n    .cortex_search_services[\"PRODUCT_INFO_SEARCH\"]\n)\nresp = cortex_search_service.search(\n    query=prompt,\n    columns=[\"SEARCH_COL\"],\n    limit=5)\n    \ntext_chunks = [row[\"SEARCH_COL\"] for row in resp.results] if resp.results else []\n\nLLM_prompt = f\"Can you summarize product benefits, value props, and a customer reference for product - {product} \\\n                using the following contextual information - {text_chunks}\"\nllm_response = complete(\"snowflake-llama-3.3-70b\", LLM_prompt)\n\nllm_response",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e0a13b3b-bba0-48f8-b563-802dbe0a339a",
   "metadata": {
    "language": "python",
    "name": "mac_updated_version"
   },
   "outputs": [],
   "source": "from snowflake.cortex import complete \n\nclass Multi_Agent_App:\n\n    # def __init__(self):\n\n    def retrieval_handler (self, client: str) -> dict:\n        \n        # Use sql to get list of currently used products and propensity-model-suggested product\n        products_used = session.sql(f\"SELECT PRODUCTS_USED FROM CUSTOMER_DATA WHERE CUSTOMER= '{client}'\").collect()[0][0]\n        suggested_product = session.sql(f\"SELECT PROPENSITY_MODEL_SUGGESTED_PRODUCT FROM CUSTOMER_DATA WHERE CUSTOMER= '{client}'\").collect()[0][0]\n\n        #retrieve the summaries and make a summary of summaries\n        conversation_summaries = session.sql(f\"SELECT DATE, NAME, TITLE, SUMMARY FROM CUSTOMER_CONVERSATIONS WHERE CUSTOMER = '{client}'\").collect()\n\n        # Format conversation summaries as text\n        conv_text = \"\\n\".join([f\"{row['DATE']} - {row['NAME']} ({row['TITLE']}): {row['SUMMARY']}\" for row in conversation_summaries])\n    \n        #create summary of summaries\n        client_history_prompt = f\"You are an expert sales trainer. Write an actionable summary of the past sales conversations based on \\\n        our intention to sell {suggested_product}. Keep it brief. \\\n        Here are the past conversations: {conv_text}\"\n        \n        client_history_summary = complete(\"claude-3-5-sonnet\", client_history_prompt)\n\n        #Retrieve relevant docuemntation for this product\n        prompt = f\"Retrieve relevant documentation for {suggested_product}\"\n        root = Root(session)\n        cortex_search_service = (\n            root\n            .databases[\"TR_MULTI_AGENT\"]\n            .schemas[\"PUBLIC\"]\n            .cortex_search_services[\"PRODUCT_INFO_SEARCH\"]\n        )\n        resp = cortex_search_service.search(\n            query=prompt,\n            columns=[\"SEARCH_COL\"],\n            limit=5)\n    \n        product_chunks = [row[\"SEARCH_COL\"] for row in resp.results] if resp.results else []\n        \n        #Pass document chunks to LLM to get a product value prop for suggested product\n        LLM_prompt = f\"Generate a concise summary of the product benefits, value props, and a customer reference for product - {suggested_product} \\\n                        using the following contextual information - {product_chunks}\"\n        product_value_prop = complete(\"claude-3-5-sonnet\", LLM_prompt)\n\n        return {\n            \"products_used\": products_used,\n            \"suggested_product\": suggested_product,\n            \"product_value_prop\": product_value_prop,\n            \"client_history_summary\": client_history_summary,\n            \n        }\n        \n\n    def agent_1_product_info(self, client: str, client_history_summary: Optional[str]) -> str:\n        \"\"\"\n        takes client and inserts into predefined prompt and passes to cortex analyst to return list of products client uses today\n        \"\"\"\n        # resp = CA.process_message(f\"What products are being used by our client {client}\")\n        # products_used = resp.iloc[:,0].to_list()\n\n        products_used = session.sql(f\"SELECT PRODUCTS_USED FROM CUSTOMER_DATA WHERE CUSTOMER= '{client}'\").collect()[0][0]\n        suggested_product = session.sql(f\"SELECT PROPENSITY_MODEL_SUGGESTED_PRODUCT FROM CUSTOMER_DATA WHERE CUSTOMER= '{client}'\").collect()[0][0]\n\n        agent_1_response = f'''The following products are used by {client} - {products_used} \\n\\n\n        \n        \\n Our propensity model has suggested the following product - SUGGESTED PRODUCT: **{suggested_product}** \\n\\n\n        \n        {client_history_summary}\n        \n        '''\n\n        return agent_1_response\n\n    def agent_2_client_web_search(self, client: str, suggested_product: Optional[str]) -> list:\n        \"\"\" \n        calls api to google client name and return top three news articles. \n        Potentially use bs4 or similar library to parse web results\n        Return list of web page text (or potentially pass to LLM to generate summary)\n        \"\"\"\n\n        # api_key = os.environ.get(\"GOOGLE_API_KEY\")\n        # cse_id = os.environ.get(\"GOOGLE_CSE_ID\")\n\n        # web_query = f\"top news for {client}\"\n        # url = \"https://www.googleapis.com/customsearch/v1\"\n        # params = {\n        #     \"key\": api_key,\n        #     \"cx\": cse_id,\n        #     \"q\": web_query,\n        #     \"num\": 3\n        # }\n\n        # top_3_results = requests.get(url, params=params)\n\n        # news_summary_list = []\n\n        # for result in top_3_result:\n        #     news_summaries_list.append(complete('snowflake-llama-3.3-70b', f'summarize the following web page {result}'))\n\n        # return news_summaries_list\n\n        if suggested_product is None:\n            suggested_product = self.retrieval_handler(client)['suggested_product']\n        news_summaries_list = []\n        news_summaries_list.append(complete('snowflake-llama-3.3-70b', f'generate a brief news summary for client {client}. \\\n        It can be fictious but should be within the realm of what that client actually does. \\\n        Start the summary with a key highlight based on what in the news relates specifically to selling Snowflake\\'s\\\n        {suggested_product} product'))\n        \n        return news_summaries_list\n\n\n    def agent_3_market_web_search(self, client: str) -> list:\n        \"\"\" \n        uses an llm to determine client industry, then ues api to google client industry and return top three articles. \n        Potentially use bs4 or similar library to parse web results\n        Return list of web page text (or potentially pass to LLM to generate summary)\n        \"\"\"\n        # api_key = os.environ.get(\"GOOGLE_API_KEY\")\n        # cse_id = os.environ.get(\"GOOGLE_CSE_ID\")\n\n        # client_market = complete('snowflake-llama-3.3-70b', f'what is the most applicable market for the company {client}')\n\n        # web_query = f\"market news for {client_market}\"\n        # url = \"https://www.googleapis.com/customsearch/v1\"\n        # params = {\n        #     \"key\": api_key,\n        #     \"cx\": cse_id,\n        #     \"q\": web_query,\n        #     \"num\": 3\n        # }\n\n        # top_3_results = requests.get(url, params=params)\n\n        # market_news_summary_list = []\n\n        # for result in top_3_result:\n        #     market_news_summary_list.append(complete('snowflake-llama-3.3-70b', f'summarize the following web page {result}'))\n        market_news_summaries_list = []\n        market_news_summaries_list.append(complete('snowflake-llama-3.3-70b', f'generate a brief market research analysis for the market that\\\n        your client {client} operates in. Focus on areas of their market that relate to what Snowflake can help with \\\n        It can be fictious but should be within the realm of how that market actually operates. \\\n        If it is not a known client/market you can just assume the client operates in the information technology market'))\n        return market_news_summaries_list\n\n    def agent_4_prep_pitch(self, client: str, product_info: Optional[str], client_news: Optional[list], market_news: Optional[list], client_history_summary: Optional[str]) -> str:\n        \"\"\" \n        passes products, client news, and market news to an LLM to come up with a rough prep pitch\n\n        \"\"\"\n        \n\n        if product_info is None:\n            product_info = self.agent_1_product_info(client, client_history_summary)\n        if client_news is None:\n            client_news = self.agent_2_client_web_search(client, suggested_product)\n        if market_news is None:\n            market_news = self.agent_3_market_web_search(client)\n        prep_pitch = complete('snowflake-llama-3.3-70b', \n                              f\"\"\"\n                              prepare a product pitch for ONLY FOR THE SUGGESTED PRODUCT based on the following product info and the client and market news \n                              past_history: {client_history_summary}\n                              product_advantages: {product_info}\n                              client_news: {client_news}\n                              market_news: {market_news}\n                              \"\"\")\n        return prep_pitch\n    \n    def agent_5_disco_questions(self, client: str, product_info: Optional[str], pitch: Optional[str], client_news: Optional[list], market_news: Optional[list], client_history_summary: Optional[str]) -> str:\n        \"\"\" \n        passes products, client news, and market news to an LLM to come up with a list of appropriate discovery questions\n        \"\"\"\n        \n        if product_info is None:\n            product_info = self.agent_1_product_info(client, client_history_summary)\n        if client_news is None:\n            client_news = self.agent_2_client_web_search(client, suggested_product)\n        if market_news is None:\n            market_news = self.agent_3_market_web_search(client)\n        disco_questions = complete('snowflake-llama-3.3-70b', \n                              f\"\"\"\n                              You are an expert sales trainer. Prepare the 5 most important discovery questions\\\n                              that the sales rep should ask in the client meeting for the SUGGESTED PRODUCT given the pitch plan to the client and market news\n                              pitch: {pitch}\n                              past_history: {client_history_summary}\n                              product_info: {product_info}\n                              client_news: {client_news}\n                              market_news: {market_news}\n                              \"\"\")\n        return disco_questions\n\n\n    def orchestrate_all_agents(self, client: str, output_file_name: str):\n        \"\"\" \n        primary function that ties all agents together and writes out a final markdown file with all prep materials\n        \"\"\"\n        st.write(\"Starting Sales Prep Agent Pipeline...\")\n\n        conversation_summary = self.retrieval_handler(client)\n        st.write(\"Collected relevant sales material & history\")\n\n        product_info = self.agent_1_product_info(client, conversation_summary[\"product_value_prop\"])\n        st.write(\"Collected Product Info\")\n        \n        client_history = self.agent_1_product_info(client, conversation_summary[\"client_history_summary\"])\n        st.write(\"Sumamrized Client History\")\n        \n        client_news = self.agent_2_client_web_search(client, conversation_summary[\"suggested_product\"] )\n        st.write(\"Collected Client News\")\n\n        market_news = self.agent_3_market_web_search(client)\n        st.write(\"Collected Market News\")\n\n        pitch = self.agent_4_prep_pitch(client, product_info, client_news, market_news, conversation_summary[\"client_history_summary\"])\n        st.write(\"Generated Pitch\")\n        \n        disco_questions = self.agent_5_disco_questions(client, pitch, product_info, client_news, market_news, conversation_summary[\"client_history_summary\"])\n        st.write(\"Generated Disco Questions\")\n        \n        markdown_doc = f\"# Prep Report for Client **{client}**\" + \\\n                       \"\\n\\n ## Product Info \\n\\n\" + product_info + \\\n                        \"\\n\\n ## Client History \\n\\n\" + client_history + \\\n                       \"\\n\\n ## Client News \\n\\n \" + ' '.join(client_news)+ \\\n                       \"\\n\\n ## Market News \\n\\n \" + ' '.join(market_news) + \\\n                       \"\\n\\n ## Proposed Pitch \\n\\n \" + pitch + \\\n                       \"\\n\\n ## Discovery Questions \\n\\n  \" + disco_questions + \\\n                       \"\\n\\n # END OF DOCUMENT - good luck with your meeting :)\"\n\n        with open(output_file_name, \"wb\") as f:\n            f.write(markdown_doc.encode(\"utf-8\"))\n\n        st.write(f\"Client prep file written to {output_file_name}!\")\n\n        return markdown_doc\n        # , products, client_news, market_news, pitch, disco_questions",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "31dd7eb8-6713-4301-a24d-7201d21ef367",
   "metadata": {
    "language": "python",
    "name": "call_mac"
   },
   "outputs": [],
   "source": "test_mac = Multi_Agent_App()\ntest_md = test_mac.orchestrate_all_agents('Wealthsimple', 'test.md')",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "5be6919f-1b57-4a31-9277-eb36d4ca9906",
   "metadata": {
    "language": "python",
    "name": "write_out_markdown_doc",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "st.write(test_md)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "b42d8e40-0c12-4358-a684-703e630159fe",
   "metadata": {
    "language": "python",
    "name": "download_report",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "download_button = st.download_button(f'Download Client Prep Report', open('test.md', 'r'), \n                                     file_name='test.md', use_container_width=True)\nif download_button:\n#    st.session_state.download_clicked = True  # Set flag in session state\n#    if st.session_state.download_clicked:\n    st.success(\"✅ File Downloaded!\")",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "dbc06e75-5fe1-456e-951b-33861c3693ed",
   "metadata": {
    "name": "ARCHIVE_MD",
    "collapsed": false
   },
   "source": "# Archive\n"
  },
  {
   "cell_type": "code",
   "id": "8ad2d8ac-d298-483b-8686-2c61c1fa2607",
   "metadata": {
    "language": "sql",
    "name": "create_network_rule_and_EAI",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "create or replace network rule CLIENT_RESEARCH_NR\n  TYPE = 'HOST_PORT'\n  MODE= 'EGRESS'\n  VALUE_LIST = ('www.businessinsider.com', 'www.techcrunch.com', 'www.google.com', 'www.googleapis.com', 'docs.snowflake.com');\n\nCREATE or replace EXTERNAL ACCESS INTEGRATION CLIENT_RESEARCH_EAI\n  ALLOWED_NETWORK_RULES = (CLIENT_RESEARCH_NR)\n  ENABLED = true;\n\n-- Make sure you enable this external access integration for the notebook!",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "6fa3d89a-afe5-49ca-92ba-ba6aa4571db4",
   "metadata": {
    "language": "python",
    "name": "cell2"
   },
   "outputs": [],
   "source": "import requests\nfrom bs4 import BeautifulSoup\n\ndef google_search(query, num_results=10):\n    headers = {\n        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.0.0 Safari/537.36\"\n    }\n    \n    # Format query for Google Search URL\n    search_url = f\"https://www.google.com/search?q={query.replace(' ', '+')}\"\n    \n    # Fetch the page\n    response = requests.get(search_url, headers=headers)\n    \n    if response.status_code != 200:\n        print(f\"Failed to fetch Google search results: {response.status_code}\")\n        return []\n    \n    soup = BeautifulSoup(response.text, \"html.parser\")\n    \n    # Extract search result links\n    links = []\n    \n    for g in soup.find_all(\"a\", href=True):\n        href = g[\"href\"]\n        print(href)\n        if href.startswith(\"/url?q=\"):  # Google uses \"/url?q=\" before the actual link\n            link = href.split(\"&\")[0].replace(\"/url?q=\", \"\")  # Clean up URL\n            links.append(link)\n    \n    return links[:num_results]\n\n# Example usage\nresults = google_search(\"Snowflake Inc\")\nprint(results)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "94645869-8510-4249-83b3-fc22b8b8b4c1",
   "metadata": {
    "language": "python",
    "name": "cell4"
   },
   "outputs": [],
   "source": "import requests\nfrom bs4 import BeautifulSoup\nr = requests.get(\"https://www.businessinsider.com/answers#snowflake\")\n# r = requests.get(\"https://www.techcrunch.com/?s=snowflake\")\n# r = requests.get(\"https://www.google.com/search?q=snowflake&oq=snowflake\")\n\nsoup = BeautifulSoup(r.text, 'html.parser')\n\n# Find all <a> tags with href attributes\nlinks = soup.find_all('a', href=True)\n\n# Extract and print the links\nfor link in links:\n    url = link['href']\n    text = link.get_text(strip=True)\n    if 'snowflake' in text.lower():\n        print(f\"URL: {url}\")\n        print(f\"Text: {text}\")\n        print(\"---\")",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "a043147d-b688-4f28-b0ab-62a9867d80d5",
   "metadata": {
    "language": "python",
    "name": "cell5"
   },
   "outputs": [],
   "source": "from googlesearch import search\n\ndef get_top_business_insider_links(search_term):\n    \"\"\"\n    Performs a Google search for a term with site:businessinsider.com and returns the top 3 links.\n\n    Args:\n        search_term (str): The term to search for.\n\n    Returns:\n        list: A list of the top 3 Business Insider links, or an empty list if none found.\n    \"\"\"\n    try:\n        query = f\"{search_term} site:businessinsider.com\"\n        search_results = list(search(query, num_results=3, stop=3, pause=2)) #pause added\n\n        business_insider_links = []\n        for url in search_results:\n            if \"businessinsider.com\" in url:\n                business_insider_links.append(url)\n\n        return business_insider_links\n\n    except Exception as e:\n        print(f\"Error during search: {e}\")\n        return []\n\n# Example usage:\nsearch_term = \"Snowflake\"\ntop_links = get_top_business_insider_links(search_term)\n\nif top_links:\n    for i, link in enumerate(top_links):\n        print(f\"Link {i+1}: {link}\")\nelse:\n    print(\"No Business Insider links found.\")\n\nsearch_term = \"Tesla\"\ntop_links = get_top_business_insider_links(search_term)\n\nif top_links:\n    for i, link in enumerate(top_links):\n        print(f\"Link {i+1}: {link}\")\nelse:\n    print(\"No Business Insider links found.\")",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "6b07e914-b245-4edf-8814-347399eea625",
   "metadata": {
    "language": "python",
    "name": "cell1"
   },
   "outputs": [],
   "source": "# from googlesearch import search\nimport requests\nfrom bs4 import BeautifulSoup\n\ndef get_top_article_text(company_name):\n    \"\"\"\n    Performs a Google search for a company name and returns the raw text of the\n    top three articles.\n\n    Args:\n        company_name (str): The name of the company to search for.\n\n    Returns:\n        list: A list of strings, where each string is the raw text of an article,\n              or an empty list if an error occurs.\n    \"\"\"\n    try:\n\n        article_texts = []\n        for url in search_results:\n            try:\n                response = requests.get(url, timeout=10) #added timeout\n                response.raise_for_status() # Raise HTTPError for bad responses (4xx or 5xx)\n                soup = BeautifulSoup(response.content, 'html.parser')\n                text = soup.get_text(separator=' ', strip=True) #added separator and strip\n                article_texts.append(text)\n            except requests.exceptions.RequestException as e:\n                print(f\"Error fetching URL {url}: {e}\")\n            except Exception as e:\n                print(f\"Error processing URL {url}: {e}\")\n\n        return article_texts\n\n    except Exception as e:\n        print(f\"Error during search: {e}\")\n        return []\n\n# Example usage:\ncompany = \"Snowflake\"\narticle_texts = get_top_article_text(company)\n\nif article_texts:\n    for i, text in enumerate(article_texts):\n        print(f\"Article {i+1}:\\n{text}\\n{'-'*40}\\n\")\nelse:\n    print(\"Could not retrieve article text.\")\n\n\n\n\n\n\nweb_query = f\"top news for Snowflake\"\nurl = \"https://www.googleapis.com/customsearch/v1\"\nparams = {\n    \"key\": '',\n    \"cx\": '',\n    \"q\": web_query,\n    \"num\": 3\n}\n\ntop_3_results = requests.get(url, params=params)\ntop_3_results",
   "execution_count": null
  }
 ]
}